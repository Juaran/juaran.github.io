---

title: 第八周学习汇报
date: 2021-4-20
category: 研一下周报

---



## VGG-CIFAR10可视化

<!-- more -->

上节说到，使用Pytorch构建的VGG-16层卷积神经网络训练CIFAR10分类数据集，最终到达了99%的分类准确率。

``` python
import torch
from torch import nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
from torchvision import datasets, transforms
import random
import numpy as np
 
from vgg import VGG16
 
 
# 加载数据集
test_dataset = \
    datasets.CIFAR10(root='cifar10',  # 数据集根目录
                     transform=transforms.ToTensor(),  # 转换为Tensor
                     download=False,  # 没有则下载
                     train=False)  # 训练数据集
 
# 加载模型参数
model = VGG16()     # 由于使用GPU训练保存的模型，加载时转为CPU类型的参数
model.load_state_dict(torch.load(f='./models/cifar10_epoch_40.pth', map_location=torch.device('cpu')))
# 读取模型参数
params = list(model.named_parameters())
 
# 读取图片数据
im, target = test_dataset.__getitem__(0)     # TensorFloat, 32, 32, 3
print("所属分类", target)
im = im.reshape(1, 3, 32, 32)     # [1, 3, width, height]
 
 
# 获取每一层的输出结果，传入层数和上一层输入
def get_conv_output(params, layer, conv_in):
    print(f"【第 {layer} 层】")
    # 读取第一层weight和bias进行卷积操作
    weight, bias = params[(layer - 1) * 2], params[(layer - 1) * 2 + 1]
    print("权重", weight[0], weight[1].shape)  # [64, 3, 3, 3]
    print("偏置", bias[0], bias[1].shape)  # [64]
    # 卷积
    conv_out = F.conv2d(input=conv_in, weight=weight[1], bias=bias[1], padding=1)
    print("卷积输出", conv_out.shape)  # [1, 64, 32, 32]
    conv_out = nn.ReLU()(conv_out)    # 激活
    # 保存特征图
    save_feature_map(conv_out, feature_num=10)
    # 池化
    if layer in [2, 4, 7, 10, 13]:
        conv_out = nn.MaxPool2d(kernel_size=2, stride=2)(conv_out)
 
    return conv_out
 
 
# 获取每一全连接层的输出结果，传入层数和上一层输入
def get_linear_output(params, layer, linear_in):
    print(f"【第 {layer} 层】")
    # 读取第一层weight和bias进行卷积操作
    weight, bias = params[(layer - 1) * 2], params[(layer - 1) * 2 + 1]
    print("权重", weight[0], "shape", weight[1].shape)  # [64, 3, 3, 3]
    print("偏置", bias[0], "shape", bias[1].shape)  # [64]
    # 全连接
    layer_out = F.linear(linear_in, weight[1], bias[1])
    print("全连接输出", layer_out.shape)
    layer_out = nn.ReLU()(layer_out)        # 激活
    # TODO 保存特征图
    # save_feature_map(layer_out, 10)
 
    return layer_out
 
 
# 保存特征图
def save_feature_map(conv_out, feature_num: int):
    feature_maps = conv_out.detach().numpy()  # Tensor转numpy
    # 降维，(1, 64, 32, 32) -> (64, 32, 32)
    feature_maps = feature_maps.squeeze()       # 512, 2, 2 -> 100
    # if feature_maps.shape[0] <= 100:
    #     feature_maps = np.expand_dims(np.expand_dims(feature_maps, 1), 1)
    print(feature_maps.shape)
    # 随机选取一个卷积核得到的特征图
    for i in range(feature_num):
        random_feature_map = feature_maps[random.randint(0, feature_maps.shape[0] - 1)]  # 第一维参数为特征图数量
        display_feature_maps.append( random_feature_map )
 
 
plt.imshow(test_dataset.data[0])
display_feature_maps = []
 
# 1-13层     卷积层
last_conv_out = im     # 第一次卷积输入为原始图像
for layer in range(1, 14):      # 前13层依次卷积，上一次卷积结果传入下一层输入
    last_conv_out = get_conv_output(params, layer, last_conv_out)
 
# 14-16层    全连接层
layer13_out = nn.Flatten()(last_conv_out)     # 展平
print("【展平】", layer13_out.shape)
last_linear_out = layer13_out     # 第一次全连接输入为13层展平结果
for layer in range(14, 17):      # 前13层依次卷积，上一次卷积结果传入下一层输入
    last_linear_out = get_linear_output(params, layer, last_linear_out)
print(last_linear_out)
print("输出分类", torch.argmax(last_linear_out, axis=1).numpy()[0])
 
 
# 绘制每一层的特征图
plt.figure()
# for i in range(1, len(display_feature_maps)+1):
for idx, i in enumerate(np.arange(0, 130).reshape(13, 10).T.reshape(130) + 1):
    plt.subplot(10, 13, idx+1)
    # print(display_feature_maps[i-1].shape)
    plt.imshow(display_feature_maps[i-1], cmap='gray')
    plt.xticks([])
    plt.yticks([])
# plt.subplots_adjust()
plt.show()
```

猫：
<table>
    <tr>
        <td><img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/cat.png" alt="cat" style="zoom: 25%;" /></td>
        <td><img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/cat_visual.png" alt="cat_visual" style="zoom:150%;" /></td>
    </tr>
</table>

参考：http://cs231n.stanford.edu/2016/

## 人脸识别

数据集来源：http://www.seeprettyface.com/mydataset_page3.html#star

500位明星人脸数据集：

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/star.jpg" alt="img" style="zoom: 50%;" />

高清数据集（512×512px） & 下载地址

数据来源：基于原始数据集重制

图片尺寸:512*512 | 图片格式:JPG | 数目:95600张 | 大小:10.57GB

下载地址： [百度网盘](https://pan.baidu.com/s/1cDmM6PjTpSoNGZ9UvPmINA)  提取码：DX6M

 

数据预处理

* 坏图，OSError: image file is truncated
* 非RGB图像：convert('RGB')
  * 4    RGBA带透明度的彩色图
  * 1    灰度图

 

人脸剪裁：

*

训练：

> Epoch 500 0 / 6734 Loss 1.5110722780227661
> Epoch 500 320 / 6734 Loss 1.2235500812530518
> Epoch 500 640 / 6734 Loss 1.367160439491272
> Epoch 500 960 / 6734 Loss 1.0074622631072998
> Epoch 500 1280 / 6734 Loss 1.079337239265442
> Epoch 500 1600 / 6734 Loss 1.2952451705932617
> Epoch 500 1920 / 6734 Loss 1.0793956518173218
> Epoch 500 2240 / 6734 Loss 1.296392798423767
> Epoch 500 2560 / 6734 Loss 1.4480328559875488
> Epoch 500 2880 / 6734 Loss 1.2232712507247925
> Epoch 500 3200 / 6734 Loss 1.2952042818069458
> Epoch 500 3520 / 6734 Loss 1.2232513427734375
> Epoch 500 3840 / 6734 Loss 1.5110729932785034
> Epoch 500 4160 / 6734 Loss 1.223249077796936
> Epoch 500 4480 / 6734 Loss 1.0073909759521484
> Epoch 500 4800 / 6734 Loss 0.935580849647522
> Epoch 500 5120 / 6734 Loss 1.3927048444747925
> Epoch 500 5440 / 6734 Loss 1.2500115633010864
> Epoch 500 5760 / 6734 Loss 1.1513397693634033
> Epoch 500 6080 / 6734 Loss 1.1512929201126099
> Epoch 500 6400 / 6734 Loss 1.1513009071350098
> Epoch 500 6720 / 6734 Loss 0.8223527073860168

可视化结果：

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/0004.jpg" alt="0004" style="zoom: 67%;" />

![image-20210425105659102](https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20210425105659102.png)