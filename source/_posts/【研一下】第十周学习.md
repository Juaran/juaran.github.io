---

title: 【研一下】第十周学习
date: 2021-5-3
category: 机器学习
tag: 周报

---



## 卡方分析

### 原理

对于使用LSB隐写的图像，其图像**统计特性**必然会发生改变。设图像中灰度值为   `j`的像素数为`hj`，`j`属于灰度范围{0, 1, 2, ...，255}。则LSB隐写比特后的像素灰度值改变规律为：`2i->2i+1`或`2i+1->2i`，而不可能出现`2i->2i-1`或`2i->2i+2`。例如：灰度值162=10100010b，改变最低有效位的值，只可能变化到10100011b=163。因此，统计像素数对`h2i`与`h2i+1`，`i`属于范围{0, 1, ..., 127}，由于嵌入比特流为随机0或1，得到二者的统计结果将会**趋近**，而未嵌入比特流的统计结果无此趋势。

### 实验

1. 绘制原图的灰度直方图
2. 绘制随机嵌入0、1比特流的隐密图的灰度直方图
3. 对比分析统计结果

``` python
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import random
 
# 原图
cover = Image.open('lena512.bmp')
cover_pixel_counts = cover.histogram()       # 统计不同灰度级数量
# 隐写图
stego = Image.open('stego.bmp')
stego_pixel_counts = stego.histogram()       # 统计不同灰度级数量
 
pixel = np.linspace(90, 109, 10)    # 获取范围94-103的10个灰度级
plt.bar(pixel, cover_pixel_counts[94: 104])     # 原图统计
plt.bar(pixel+0.8, stego_pixel_counts[94: 104])     # 隐密图统计
plt.show()
```

![](https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20210504102427318.png)

以上统计结果，蓝色柱状图为原图统计结果，橘色柱状图为隐密图统计结果。由于灰度级过多，挑选90-109的20个灰度值展示。两两对比`2i`和`2i+1`的灰度数量，可以发现原图的统计量差总是大于隐密图的统计量，特别是在灰度级98、99时，原图相差一大截，隐写后则几乎持平。因此，由统计结果中灰度数量变化较为平缓的特点可以怀疑使用了LSB隐写。

由以上实验，虽然隐写改变了`h2i`和`h2i+1`的值，但`h2i+h2i+1`始终保持不变，当嵌入量足够多时，嵌入比特非0即1（服从0-1离散均匀分布），得到`h2i`和`h2i+1`的概率各为50%。综上，隐密图片灰度值对`(h2i, h2i+1)`满足以上分布性质，而原图不具备，根据卡方检验方法，`h2i`的期望值为`h2i*=(h2i+h2i+1)/2`，有以下卡方检验：
$$
\chi^2 = \sum_{i=0}^{k=127} \frac {[h_{2i} - h_{2i}^*]^2} {h_{2i}^*}
$$

``` python
h = stego_pixel_counts
sum([(h[2*i] - sum(h[2*i:2*i+2])/2)**2 / (sum(h[2*i:2*i+2])/2+0.000001) for i in range(0, 127)])
```

> 隐密图卡方检验值：50.46143061544536
>
> 原图卡方检验值：220.25579551083484

| P    | 0.995  | 0.975  | 0.2     | 0.1     | 0.05    | 0.025   | 0.02    | 0.01    |
| ---- | ------ | ------ | ------- | ------- | ------- | ------- | ------- | ------- |
| 128  | 90.543 | 98.576 | 141.235 | 148.885 | 155.405 | 161.209 | 162.963 | 168.133 |

查自由度为128的卡方分布表，隐写图的检验值为50，小于90时对应的99.5%的置信度，概率几乎为1；而原图的检验值220，超出168时对应的1%的置信度，概率几乎为0。因此，卡方检验可以用于区分LSB隐写的图像。

### 总结

针对LSB嵌入算法嵌入比特位随机分布的特点，卡方检验可以轻易识别出这种分布规律，原图则在最低位与高位值存在内容相关性，不服从分布特性。也正因此，这种检验方法在嵌入率高时越有效，低隐写率呈现的是隐写部分服从该分布而未隐写部分无相关性，对于伪随机嵌入同理。

**参考**：https://www.renrendoc.com/paper/110622186.html

https://www.zhihu.com/question/301957087

https://wenku.baidu.com/view/3613dca3b8f67c1cfbd6b841.html

对LSB隐写攻击的其他手段参考：[基于LSB的隐写与隐写分析](https://wenku.baidu.com/view/7809ab0957270722192e453610661ed9ad51557b.html)

## LSB Matching

在之前的Simple **LSB Substitution**中，LSB嵌入的比特随机且嵌入信息与原图无关，每个选择的像素最低有效位被隐藏消息的一位替换，偶数像素值不变或+1，奇数像素值不变或-1，这样使得`2i`与`2i+1`的像素值对数量呈现趋近趋势，使用统计方法可以可靠检测出这种特性。

**LSB Matching**是LSB的改进算法，也被称为`±1嵌入`，在必须更改该位时（隐藏消息位与LSB不同）将像素值随机加1或减1，这样既保留了LSB替换的特性，又保证在统计角度难以检测，不会出现具有相关性的像素对。理论分析和实践表明，尽管只做了简单的随机嵌入，这种嵌入方法比替换方法的隐写分析更为困难，目前（2010年以前）对于LSB替换的攻击方法效果都不是很好。

[1] J. Mielikainen, "LSB matching revisited," in *IEEE Signal Processing Letters*, vol. 13, no. 5, pp. 285-287, May 2006, doi: 10.1109/LSP.2006.870357.（原文在IEEE要钱看不到）

[2] [Jiaohua Qin, Xuyu Xiang and Meng Xian Wang, 2010. A Review on Detection of LSB Matching Steganography. *Information Technology Journal, 9: 1725-1738.*](https://scialert.net/fulltext/?doi=itj.2010.1725.1738#ref) （找了篇详细的综述文章）

[3] https://blog.csdn.net/u012939857/article/details/68940859

![image-20210505113059944](https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20210505113059944.png)

**代码实现**：

``` python
import random
import numpy as np
from PIL import Image
 
 
def LSB_matching(cover_img):
    im = Image.open(cover_img)
    stego_im = np.ones((im.height, im.width))
    for i in range(im.height):
        for j in range(im.width):
            # 随机嵌入-1, 0, 1, 模拟LSM匹配算法 正负1嵌入 和 保持不变 的情形
            stego_im[i][j] = im.getpixel((j,i)) + random.randint(-1, 1)
    stego = Image.fromarray(stego_im).convert('L')
    stego.save('stego.bmp')
 
LSB_matching('lena512.bmp')
```

对LSB匹配的隐写分析方法经历了以下几个阶段：

1. Harmsen 和 Pearlman (2003)提出了一种使用直方图特征函数分析(HCF)的检测方法
2. Ker (2005a)扩展了 Harmsen 方法，提出了两种新的方法: (1)用下采样图像标定质量输出中心(COM) ，(2)用邻接直方图代替通常的直方图
3. Fridrich 等人(2005)提出了一种最大似然估计器，用于估计非自适应 ± k 嵌入图像中嵌入变化的次数
4. (2008)提取为小波域中的噪声残差矩和灰度直方图(进一步称为ALE检测器)中局部极值放大的统计量的特征。
5. 小波绝对力矩(WAM)阶梯分析仪
6. （2010）差分像素邻接矩阵（SPAM）模型

## 通用隐写分析

一般专用隐写分析技术对特定的隐藏方法具有较高的准确性, 但对其他方法无效；相反, 通用隐写分析技术可以同时检测许多隐藏方法, 甚至包括未知的新方法。在深度学习之前，传统的通用隐写分析都是从图像的统计特征入手，构建特征提取模型。随着隐写算法的改进，从LSB替换到LSM匹配，再到**自适应隐写方法**的出现，隐写前后图像的统计特性基本保持一致，隐写分析难度也越来越大。

根据不同的特征提取方式，通用隐写分析可分为基于图像质量标准的隐写分析特征、基于统计矩的隐写分析特征、基于相邻像素相关性的隐写分析特征。其中，差分像素邻接矩阵（SPAM）法是性能最好的通用隐写检测方法。

[1] 张军,熊枫,张丹.图像隐写分析技术综述[J].计算机工程,2013,39(04):165-168+172.

[2] 彭伟,胡宁,胡璟璟.图像隐写分析算法研究概述[J].计算机科学,2020,47(S1):325-331.

**自适应隐写**发展：

根据构造的嵌入失真函数计算载体图像中元素发生更改所引起的失真，利用隐写编码控制秘密信息的嵌入位置，在最小化图像总体嵌入失真的同时保证秘密信息的准确提取。

* EA(Edge Adaptive) 边缘自适应
* HUGO(Highly Undetectable steGO)是第一个基于“嵌入失真函数+STCs编码”的自适应隐写算法，应用于BOSS（Break our Steganographic System）隐写分析竞赛。--> 设计目的是对抗SPAM二阶特征的分析
  * [空域自适应隐写算法HUGO----原理，代码及解析](https://zhuanlan.zhihu.com/p/345915051)

* 空域自适应隐写
  - WOW（Wavelet Obtained Weights）
  - S-UNIWARD（Spatial UNIversal WAvelet Relative Distortion）
  - HILL（HIgh-pass, Low-pass, and Low-pass）
* JPEG域自适应隐写（变换域）
  - YASS
  - UED（Uniform Embedding Distortion）
    - SC-UED（Single Coefficient UED）
    - JC-UED（Joint Coefficients UED）
  - J-UNIWARD（JPEG UNIversal WAvelet Relative Distortion）

## SPAM

[1] [PEVNÝ T, BAS P, FRIDRICH J. Steganalysis by subtractive pixel adjacency matrix[J]. IEEE Transactions on Information Forensics & Security, 2010, 5(2):215-224.](https://hal.archives-ouvertes.fr/hal-00541410/document)

[2] 杨雪,杨榆,雷敏.基于SPAM和特征优化的通用隐写分析算法改进[J].成都信息工程大学学报,2016,31(01):65-69.

### 特征提取

首先，计算`m x n`图像每一像素与八个领域的像素差值，得到八个像素差分矩阵D（difference array D）。以水平方向为例，其他方向同理：
$$
D_{i,j}^{\to} = I_{i,j} - I_{i,j+1}
$$
以上计算从左到右的像素差值时，*i* *∈ {*1*,...,m**}**, j* *∈ {*1*,...,n* *−* 1}. 其他方向计算时需要注意边界。其他7个方向的差分矩阵分别记为`D←i,j`,`D↓i,j`,`D↑i,j`,`D↘i,j`,`D↖i,j`,`D↙i,j`,`D↗i,j`。

其次，用一阶马尔可夫过程（Markov process）对差分阵列D进行建模。马尔科夫模型的状态空间为像素差值Xn={-510, ..., -255, ..., -4, -3, -2, -1, 0, 1, 2, 3, 4, ..., 255, ..., 510}，从像素差值`u`转移到像素差值`v`的过程为一阶马尔科夫链，则状态转移概率矩阵大小为`（2x510+1）^2`。定义水平从左到右的差值转移概率矩阵`M→u,v`为：
$$
M^→_{u,v} = Pr(D^→_{i,j+1} = u \ | \ D^→_{i,j} = v)
$$
即：在当前像素位置像素差值`Di,j=u`，转移到下一像素位置的像素差值`Di,j+1=v`的转移概率是条件概率`Pr(u|v)=Pr(u,v) / Pr(v)`。使用阈值`T`限制`u, v ∈ {−T,...,T}`，从而状态转移矩阵大小为`(2T +1)^2`，去除了差值过大的转移概率计算。

使用二阶马尔科夫过程对差分矩阵D进行建模，进一步得到像素差值二次转移的概率矩阵。定义为：
$$
M^→
_{u,v,w} = P r(D^→
_{i,j+2} = u \ | \ D^→
_{i,j+1} = v, \ D^→
_{i,j} = w)
$$
即差值从`w`转移到`v`再转移到`u`的概率。使用阈值`T`限制`u, v, w ∈ {−T,...,T}`，矩阵大小为`(2T +1)^3`。

最后，为了降低特征维数，作者做了一个合理的假设，即自然图像中的统计量在镜像和翻转方面是对称的，因此，分别平均水平矩阵和垂直矩阵，然后平均对角矩阵，以形成最终的SPAM特征集`F1st`，`F2nd`，定义如下：
$$
F_{1,...,k} = \frac1{4} \ [M^→ + M^← + M^↓ + M^↑] , \\
F_{k+1,...,2k} = \frac1{4} \ [M^↘+ M^↖ + M^↙ + M^↗]
$$
对于一阶SPAM特征，一共有`2k=2(2T+1)^2 `个特征，前k个特征对应水平和垂直四个方向的转移概率矩阵（大小为`(2T+1)x(2T+1)`）均值转为一维向量，后k个特征对应主对角线和副对角线四个方向的转移概率矩阵均值转为一维向量。对应的，特征`F1`为差值`-T`转移到`-T`的概率均值，特征`F2`为差值`-T`转移到`-(T+1)`的概率均值，依次类推，特征`Fk`为差值`T`转移到`T`的概率均值。

在论文中，为了降低维数，一阶特征取T=4、8，得到162个、578个特征；二阶特征取T=3，得到686个特征。模型复杂度取决于马尔科夫过程阶数和差值范围T。以上特征提取过程如下图所示：

![image-20210507110219942](https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20210507110219942.png)

作者在末尾解释这个过程：

> 差分数组的计算可以解释为使用核[−1,1]的高通滤波，这实际上是最简单的边缘检测器。滤波抑制图像内容并暴露半移噪声，从而导致更高的信噪比SNR。这个主意借鉴了WAM计算小波域噪声残余矩。

### 实验过程

首先，下载论文中的SPAM特征提取代码(http://dde.binghamton.edu/download/spam/)，在Windows下通过Visual Studio打开项目，编译相关静态和动态链接库（费了我不少劲），Debug得到SPAM.exe。对测试图片输出一阶SPAM特征`a.txt`，然后使用LSB matching算法隐写该图片，对隐写图输出一阶SPAM特征`b.txt`。

> $ SPAM.exe --singleFile 1.png -T1 4 --oFile1st a.txt
> processing 1.png
>
> $ SPAM.exe --singleFile stego.png -T1 4 --oFile1st b.txt
> processing stego.png

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20210507112255179.png" alt="image-20210507112255179" style="zoom: 50%;" />

得到了两组差值阈值为4、共162维的一阶像素差值概率转移矩阵SPAM特征，可视化这些特征，对比隐写前后SPAM特征变化：

``` python
import matplotlib.pyplot as plt
 
x = np.linspace(1, 162, 162)
y1 = list(map(lambda x:float(x), list('a.txt')))    # 提取a.txt数值列表
y2 = list(map(lambda x:float(x), list('b.txt')))    # 提取b.txt数值列表
plt.plot(x, y1)
plt.plot(x, y2)
plt.yticks([])
plt.show()
```

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20210507112803231.png" alt="image-20210507112803231" style="zoom:80%;" />

图中蓝色曲线代表原图的一阶SPAM特征，橘色曲线代表LSB匹配算法隐写图的一阶SPAM特征。原图左侧峰值对应特征为差值`0->0`在水平、垂直方向的状态转移概率均值，右侧峰值对应差值`0->0`在对角线方向的状态转移概率均值；由随机加减一嵌入后的隐写图像的SPAM特征表现出了不一样的特征，左侧峰值分别对应`-1->1`、`0->0`、`1->-1`，右侧同理。

对此隐写前后特征的变化解释为：有更多的原本应为`-1->-1`和`-1->0`的转移概率在隐写之后受到抑制，从而`-1->1`的转移概率增加；有更多的原本应为`0->-1`和`0->1`的转移概率在隐写之后受到抑制，从而`0->0`的转移概率增加；有更多的原本应为`1->-2`和`1->0`的转移概率在隐写之后受到抑制，从而`1->-1`的转移概率增加。

另外，原图的特征也很明显，上半部分是天空，像素值基本都是255，下半部分是山地，像素值低。因此差值大多数会聚集在-1，0，1周围，这也符合上图的统计规律。

不同隐写率下提取特征对比：隐写率越低，SPAM特征越接近原图。

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20210508095210947.png" alt="image-20210508095210947" style="zoom: 80%;" />

**HUGO**自适应隐写下的一阶SPAM特征：0.5bpp，已经看不出来差异了。

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20210508120334391.png" alt="image-20210508120334391" style="zoom: 67%;" />

### 思考

SPAM特征提取像素差值在有限范围[-T, T]内，目的是为了降低马尔科夫状态转移矩阵大小从而降低特征维数，以便于后续分类（论文使用SVM分类器）。由此带来的缺陷是，对于差值较大、不在T范围内的像素不会被提取为SPAM特征，后续隐写算法HUGO等正是基于二阶SAPM特征的这个特点，将信息位隐藏在图像边缘、轮廓地带，从而不被检测。

有以下想法：

* 对取得的一阶、二阶SPAM特征，使用神经网络分类训练
* 不进行降维，保留图像的所有像素差值转移概率，但差值范围由原来的[-510, 510]取绝对值为[0, 255]，得到256x256大小的概率转移矩阵。由对称性，取`F=1/8(M_各方向)`，不转换维度。使用CNN等神经网络对特征矩阵进行分类任务训练，或许可以得到更好的效果！

## SPAM+CNN

### LSBmatching

**网络模型**：输入为一组（cover，stego）的一阶SPAM特征，大小为2x162，使用9个2x2卷积核和三个全连接层组成简单模型。

``` python
self.net = nn.Sequential(
            # input size: [batch, channel, 2, 162]
            nn.Conv2d(in_channels=1, out_channels=9, kernel_size=2, padding=0),
            nn.ReLU(),      # [1, 9, 1, 161]
            nn.Flatten(),   # [1, 1449]
            nn.Linear(1449, 100),
            nn.ReLU(),
            nn.Linear(100, 10),
            nn.ReLU(),
            nn.Linear(10, 2),
            nn.ReLU(),
        )
```

**第一次实验**：LSBmatching，隐写率1.0bpp

8000训练集+2000测试集，99.9%准确率。训练时间：20s（SVM需要17h）。

> (venv) $ python3 spam_net.py
> Epoch 1 50 / 10000 Loss 0.6870915293693542
> Epoch 2 50 / 10000 Loss 0.5190097689628601
> Epoch 3 50 / 10000 Loss 0.11720794439315796
> Epoch 4 50 / 10000 Loss 0.0542331263422966
> Epoch 5 50 / 10000 Loss 0.017127415165305138
> Epoch 6 50 / 10000 Loss 0.027075674384832382
> Epoch 7 50 / 10000 Loss 0.02605585567653179
> Epoch 8 50 / 10000 Loss 0.011004366911947727
> Epoch 9 50 / 10000 Loss 0.01031360775232315
> Epoch 10 50 / 10000 Loss 0.04042639583349228
> Model saved.
> Validate accuracy:0.999

**第二次实验**：LSBmatching，隐写率0.5bpp

使用已训练的隐写率1.0bpp的模型，1000测试集，97.8%准确率。

> Validate accuracy:0.978

**第三次实验**：LSBmatching，隐写率0.25bpp

使用已训练的隐写率1.0bpp的模型，500测试集，94.4%准确率。

> Validate accuracy:0.944

**第四次实验**：HUGO，隐写率0.5

使用已训练的LSB-matching隐写率1.0bpp的模型，1000测试集，71.5%准确率。

> Validate accuracy:0.715

### HUGO

HUGO自适应隐写前后的一阶SPAM特征几乎无差别，因此未经训练得到70%的准确率已经不错了。后续对HUGO隐写的特征向量进行训练，再做测试。向学姐要来10000张BOW2数据集原图和不同程度HUGO隐写率的隐写图。

#### 实验

采用同样方法得到一阶SPAM特征，差值范围[-4, 4]。训练HUGO隐写图像bpp=0.5情况下的特征分类模型，训练模型和实验数据如下：

``` python
self.net = nn.Sequential(
            nn.Conv2d(in_channels=1, out_channels=49, kernel_size=2, padding=0),
            nn.ReLU(),      # [1, 9, 2, 686]
            nn.Flatten(),   # [1, 49*685]
            nn.Linear(49*685, 1024),
            nn.ReLU(),
            nn.Linear(1024, 100),
            nn.ReLU(),
            nn.Linear(100, 10),
            nn.ReLU(),
            nn.Linear(10, 2),
            nn.ReLU(),
        )
```

* 隐写率0.5bpp所得模型对自身训练集验证结果：

> 10轮：Validate accuracy:0.8936
> 30轮：Validate accuracy:0.9696
> 40轮：Validate accuracy:0.9782
> 70轮：Validate accuracy:0.9984
> 100轮：Validate accuracy:1.0

使用100轮得到的模型验证结果高达100%，显然存在过拟合问题。

* 使用以上模型检测不同隐写率的HUGO图像（相同载体图不同隐写率）：

> 0.4bpp：Validate accuracy:0.9649
> 0.3bpp：Validate accuracy:0.9204
> 0.2bpp：Validate accuracy:0.8566

* 验证集，载体图与隐写图均与训练集不同，2000张，0.5/0.4/0.3/0.2bpp验证结果：

> 05bpp：Validate accuracy:0.835
> 04bpp：Validate accuracy:0.7945
> 0.3bpp：Validate accuracy:0.7375
> 0.2bpp：Validate accuracy:0.6615

* 在原有模型训练0.2bpp隐写数据得到微调模型，但测试结果比上面仅增加1%准确率。

以上实验结果表明，测试集所得模型可以适用于该测试集所用载体图隐写的不同HUGO隐写率图像，但对验证集上与之不同载体图的数据预测效果较低，究其原因是网络模型过于简单，过拟合严重，模型泛化能力差，对未知数据的识别能力差。

再究其原因，低隐写率图像的二阶SPAM特征与原图几乎一致，SPAM特征本质是像素差值矩阵，而像素差值的马尔科夫转移概率矩阵范围仅在[-3, 3]内，又HUGO这类自适应隐写算法本身就是为了克服二阶SPAM特征而生，这使得隐写像素在图像边缘、纹理、边界地带，从而像素差值远远超过[-3, 3]的范围，就是说能够提取到的特征已经微乎其微了。

为了克服这个问题，扩大SPAM特征矩阵大小，将矩阵差值T设大些再进行试验。

**修改网络模型**，通道数改为2，即将原来的一维向量(cover, stego)堆叠成二维，原本的一维特征也化为二维，即二维的转移概率矩阵；使用的数据集为一阶SPAM特征，差值范围T=8，训练使用10000张原图+0.5bpp隐写图。

``` python
self.net = nn.Sequential(
            # input size: [batch, 2, 2, -1]
            nn.Conv2d(in_channels=2, out_channels=17, kernel_size=2, padding=0),
            nn.ReLU(),      # [1, 9, 1, 161]
            nn.Flatten(),   # [1, 1449]
            nn.Linear(17 * (17 * 17 - 1), 1024),
            nn.ReLU(),
            # nn.Dropout(0.5),
            nn.ReLU(),
            nn.Linear(1024, 100),
            nn.ReLU(),
            nn.Linear(100, 10),
            nn.ReLU(),
            nn.Linear(10, 2),
            nn.ReLU(),
        )
```

经100轮训练，对2000张验证集数据进行验证，0.5bpp的隐写数据准确率由之前实验的83.5%提高到88.5%，0.4bpp提升了6%，0.3bpp提升了7%，0.2bpp提升了8%：

> 0.5bpp：Validate accuracy:0.8855
> 0.4bpp：Validate accuracy:0.858
> 0.3bpp：Validate accuracy:0.8085
> 0.2bpp：Validate accuracy:0.735

再使用0.5bpp所得模型微调0.3bpp数据集，所得模型再次进行验证，略微提升了1-3%。

接下来的实验准备直接训练0.2bpp的数据集，

------

#### 扩大阈值

再回到问题的根本，二阶SPAM特征在HUGO等自适应隐写情况下已经提取不到明显的噪声特征，如果把阈值扩大到128，对比差值为[-128, 128]范围0.2bpp下的SPAM特征：

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20210509082708253.png" alt="image-20210509082708253" style="zoom: 80%;" />

如图所示，得到的转移概率矩阵展开共有132098维，这也可以解释为何传SVM分类器等无法取得更好的隐写分析率。缩小范围，直接截取矩阵的257x64部分，共16448个特征，并加入0.5bpp作对比：
<table>
<tr>
<td>
<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20210509092103009.png" alt="image-20210509083914405" style="zoom: 80%;" />
</td>
<td>
<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20210509092211147.png" alt="image-20210509084008890" style="zoom: 80%;" />
</td>
</td>
</table>

此时，特征对比以及很明显，如果继续降低维度，能更清晰的看到特征差异，但如果维度过低，所得特征具有局限性，不能作为其他图片的提取特征。

**经过合理性考量，将一阶SPAM差值阈值T设为T=64，得到（2T+1）^2约为2^9，仅取矩阵上四分位部分，即大小129x32约4096个特征向量。**

使用批处理执行命令：

> SPAM.exe --singleFile 图片路径 -T1 64 --oFile1st 图片名.txt

不幸的是，**在训练时一直未能收敛**。原因可能是**特征之间关联性不强**，表现在统计图中是有很多尖锐的点，导致难以区分特征差异。以下是之前能达到收敛的特征和当前提取特征对比：

<table><td>
<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20210507112803231.png" alt="image-20210507112803231" style="zoom:75%;" />
</td><td>
<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20210509161239887.png" alt="image-20210509161239887" style="zoom:100%;" />
</td></table>

得到的结论是，虽然能够提取自适应隐写图像的高维特征，但这些特征杂乱无序，难以训练。

（未完待续......）