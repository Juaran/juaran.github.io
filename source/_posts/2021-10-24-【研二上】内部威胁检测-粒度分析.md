---

title: 【研二上】内部威胁检测-粒度分析
category: 机器学习
tag: 周报
date: 2021-10-25

---



### GCN-内部威胁检测

> Jiang, J., Chen, J., Gu, T., Choo, K.-K. R., Liu, C., Yu, M., … Mohapatra, P. (2019). [*Anomaly Detection with Graph Convolutional Networks for Insider Threat and Fraud Detection*]()*. MILCOM 2019 - 2019 IEEE Military Communications Conference (MILCOM).*
>
> doi:10.1109/milcom47813.2019.9020760

* 第一个使用GCN模型用于内部威胁检测和欺诈检测的工作
* 提供了一种增强稀疏图节点间结构信息增强的方案（具体地，计算用户特征相似性）
* 提供了一个基于GCN算法的异常检测系统的通用框架

#### 异常检测框架

![image-20211020191248836](https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20211020191248836.png)

* 特征提取模块：从日志数据中提取用户行为特征和内容特征，共31维：
  * 登录/注销特征-3：每日登录/注销次数，下班时间登录/注销次数，登录/注销的PC数量
  * 设备特征-3：每日设备连接数，下班时间设备连接数，设备连接的PC
  * 文件特征-5：每天不同类型文件数量，总文件数，下班时间操作文件数，exe文件数，操作文件的PC数量
  * 邮件特征-7：每日发送邮件数，发给外部的邮件，内部发送的邮件，平均邮件大小，接收人数，话题相关的邮件，情感相关的邮件
  * 网页特征-5：每日浏览的网页数，维基解密相关的网页，情绪相关的网页，话题相关的网页，键记录器相关的网页

* 图结构增强模块：直接使用邮件关系建立用户图可能会丢失重要信息，而且有些用户是孤立的。具体地，在以邮件关系为边的用户图的基础上，对于没有相互连接的两个节点，计算节点**特征余弦相似度**，得到边权重：

$$
A(i,j) = \omega \ * \ cos(F_i,F_j) + (1-\omega) * C_{ij}
$$

​        根据以上权重函数得到新的图邻接矩阵表示，以0.5为阈值将边表示分为实线和虚线，最终图结构如下所示：

![image-20211020195843584](https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20211020195843584.png)

* GCN设计模块：两层的GCN网络模型，输入图结构和节点特征，ReLU激活函数、softmax分类

![image-20211020200450802](https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20211020200450802.png)

#### 实验及结果

数据集：CERT-r4.2，图节点和边数、数据集划分如下表，其中加权后的图为全连接图

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20211020202908693.png" alt="image-20211020202908693" style="zoom:80%;" />

实验对比：Random Forest、Logistic Regression、SVM、CNN

#### 疑问和思考

1. 构建图时，使用邮件关系强连接节点，使用特征相似度弱连接节点，两者结合构成加权图。如果不考虑邮件关系，仅通过节点相似度进行连接，是否会更好？因为使用特征相似度连接似乎更具有说服力
2. 文中提到对每个用户提取31维特征，但具体字段有些不清楚。原始数据特征向量化是主要工作，文末提到：

>  We also thank Chenggang Jia for his contribution in the processing of the raw data from CMU dataset.

负责数据处理的贾成刚同学去哪找？

3. 作者在实验时使用训练集：160个正常节点+40个异常节点，测试集：170个正常节点+30个异常节点（看到这里时三观炸裂）。这与实际情况非常不符，如果使用数据集CERT-r6.2，3955个正常节点+5个异常节点，或使用真实数据，这篇论文毫无价值
4. 在构建图节点时，计算节点特征的余弦相似度得到带相似度权的边，是否有更好的相似度计算方法？

### 内部威胁数据粒度分析

在数据预处理过程中发现了github: [Feature extraction for CERT insider threat test dataset](https://github.com/lcd-dal/feature-extraction-for-CERT-insider-threat-test-dataset)

代码指向的paper: 使用机器学习方法分析内部威胁检测数据的粒度分级

> D. C. Le, N. Zincir-Heywood and M. I. Heywood, "Analyzing Data Granularity Levels for Insider Threat Detection Using Machine Learning," in *IEEE Transactions on Network and Service Management*, vol. 17, no. 1, pp. 30-44, March 2020, doi: 10.1109/TNSM.2020.2967721.

**Data granularity**: 指的是数据的细化程度，越明细的数据包含的信息越多，同时也越难解读，所以一般根据问题需求不同会挑选不同粒度的数据来分析。

**Insider threat**：在CERT内部威胁中心最近的一份技术报告中定义为由恶意或无意的内部人员实施的威胁，他们被授权访问组织的网络、系统和数据，对组织信息、信息系统或员工的机密性、完整性、可用性或身体健康产生负面影响。与内部威胁有关的恶意活动既可由恶意的内部人士故意进行，如信息系统破坏、知识产权盗窃和披露机密信息，也可由无意的内部人士进行，如用户在使用授权资源时的疏忽。

**研究面临的问题**：

1. 与传统的入侵检测任务不同，内部威胁检测的许多挑战来自于内部人员被授权访问组织的计算机系统，并熟悉组织的安全层。

2. 此外，在大多数组织中，内部人士有恶意的活动很少发生。因此，可用于描述该活动的数据通常很少见，而且没有得到很好的记录。
3. 最后，内部威胁检测的挑战可能来自于需要处理和调查组织环境中的各种数据类型，从网络流量、Web和文件访问日志到电子邮件历史或员工信息。可用的数据也因组织机构的不同而有显著的不同。因此，只有一小部分组织拥有工具和（人力）资源，可以从收集到的监控数据来解释用户的行为和意图。

论文提出并评估了一个以用户为中心的内部威胁检测的工作流程，<u>从数据收集和预处理，到使用ML模型的数据分析，以及警报报告和分析</u>。系统流程如下：(我们重点关注数据预处理部分)

1. 数据收集：行为日志(实时数据)，用户信息(上下文信息)
2. 数据预处理：构造特征向量表示用户行为信息，以不同的数据粒度级别
3. 使用四种ML算法分析特征向量
4. 结果以不同的格式呈现，并向系统分析师提供了详细的分析（现实场景中是必要的）

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20211022104013968.png" alt="image-20211022104013968" style="zoom:80%;" />

#### 数据预处理

特征提取：主要是各项数据的频率特征和统计特征，但不包括内容数据（出于用户隐私考虑）

粒度分级：作者根据持续时间和操作次数，将数据按周、天、会话统计

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20211022112401272.png" alt="image-20211022112401272" style="zoom:80%;" />

基于会话的数据具有隔离恶意操作的用处，因为恶意用户倾向于在特定的会话中执行恶意操作，而在同一天或一周中的其他会话可能仍然是正常的。此外，由于会话的持续时间通常比一天短得多，因此当检测到恶意实例时，这种数据类型也可以允许更快的系统响应。

由于一个会话可能持续数个小时，由数百个操作组成，作者进一步探索每个会话数据实例中统计的数据量与系统对恶意行为的潜在系统响应时间之间的平衡（会话时间过长、操作过多不利于ML学习）。最终通过统计分析，得出子会话持续时间划分的超参数`i={2,4}`，子会话操作次数划分的超参数`j={25,50}`。

#### 数据概述

运行论文提供的代码，得到了按以上不同数据粒度级别划分的特征数据：

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20211022202346686.png" alt="image-20211022202346686" style="zoom: 80%;" />

不同粒度的数据特征按恶意场景分布如下(r5.2数据为例)。可以看出：内部威胁的场景占比极少且不同场景的数量不均衡；粒度越细，捕获的恶意场景越多；恶意场景的时间跨度、操作次数跨度不一，这意味着有些恶意操作经过较长时间执行避免被发现：

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20211023122111622.png" alt="image-20211023122111622" style="zoom:80%;" />

#### 实验设置

现实约束：现实环境中，用于训练检测系统的标记数据是稀缺的。因此，实验应该从有限的已知标签数据中训练得到模型，然后得到模型在现实网络系统上的真实评估。由此，为了模拟现实情况，**训练集由400个(20%)用户的前37周(一半)数据构成，包含18%的正常用户和34%的恶意用户**。这样，模型通过少部分数据预测未知数据，以确保实验是现实可信的。

作者采用了四种机器学习方法：LR、NN、RF、XG；数据集使用CERT r5.2：99个恶意用户，1901个正常用户；评估方法：DR(recall)、FPR、Pr、F1，采用f1性能指标作为模型表现能力。

为了说明ML在解决现实网络世界环境问题上面临的挑战，作者对比了ML在理想情况下和现实情况下的评估结果。理想情况下实验条件是：将全部用户的50%用于训练，而模拟的现实条件是：20%的用户数据且只有前半段时间。

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20211024115759518.png" alt="image-20211024115759518" style="zoom:80%;" />

以上结果可以看出，理想情况下的模型评估显著优于现实条件。这意味着不能采用典型的全局数据分割训练方法。

然后，作者分别基于用户分类和基于实例分类。即只要有一条数据实例是恶意的，那么该用户判定为恶意用户；一条数据实例预测为恶意行为，但该用户其他的数据实例可能大部分是正常的。以此来检出恶意用户和恶意行为。

