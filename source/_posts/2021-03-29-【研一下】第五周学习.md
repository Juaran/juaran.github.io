---

title: 【研一下】第五周学习汇报
date: 2021-3-30
category: 机器学习
tag: 周报

---



# Day 01

### 卷积神经网络（Convolutional Neural Network）

理解：卷积神经网络结构主要分成卷积和下采样（池化）操作。

对于输入特征为高维的数据如图像（28*28\*1长、宽、通道数），将其拉伸为一维向量（784个像素）并建立模型进行分类，训练效果必然有所缺陷，存在拉伸后像素之间的纹理等关联性丢失等问题，在图像很复杂的情况下不适合用此方式。

在卷积网络结构中，输入特征往往以高维张量表示，通过与多个卷积核（filter）作矩阵运算（卷积操作）可提取图像的边缘信息、纹理信息等（视不同算子而定），这些算子往往是1\*1、3\*3、5\*5的带有不同权重Weight信息的矩阵，图像经过一次卷积后得到一个比原图像“小一圈”的图像结构（feature map），可看做一个神经元；但此时图像依然很大，下采样（sub sampling）通过提取图像局部像素（如四邻域）的最大值（称为最大池化）或平均值（称为均值池化）将图像最大限度的降低维数，但依然保留了图像的基本特征。重复卷积和池化的过程，每一个过程都可以看做一个隐藏层，将图像从最初输入时的高维度降到输出时的低维度，最终经过激活函数到输出层，可以理解为图像越变越小，但越叠越厚。

### tf.nn.conv2d

* input    输入图像，格式为float32、64
  * [batch, height, width, channels]    四维
* filter    卷积核，[3, 3, 1, 1]，3*3卷积核，输入图像通道1，卷积核个数1
* strides  步长，[1, stride, stride, 1]，横向纵向移动步长
* padding  零填充
  * "SAME"    遇到边缘填充
  * "VALID"    边缘不填充

卷积示例：

``` python
import matplotlib.pyplot as plt
 
plt.imshow(train_x[0], cmap="Greys")
input_img = train_x[0]
input_img.shape
```

> (28, 28)    输入图像28*28

``` python
input_img = input_img.reshape([1, 28, 28, 1])
input_img.shape
```

> (1, 28, 28, 1)     2D图像转为4D输入格式

``` python
sobel = tf.constant(value=[[-1, 0, 1], [-2, 0, 2], [-2, 0, 1]], shape=(3, 3, 1, 1))
sobel.shape
```

> TensorShape([3, 3, 1, 1])    定义sobel轮廓提取算子

```  python
strides = [1, 1, 1, 1]
padding = "SAME"
out_img = tf.nn.conv2d(input=input_img, filters=sobel, strides=strides, padding=padding)
out_img = tf.reshape(out_img, (28, 28))
plt.imshow(out_img, cmap='Greys')
```

> 卷积得到结果为(1, 28, 28, 1)，转为二维特征图像显示

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20210330102909254.png" alt="image-20210330102909254" style="zoom:50%;" />

### tf.nn.max_pool

* value 同conv2d的input图像输入
* ksize  池化窗口大小，[1, ksize, ksize, 1]
* strides  步长，[1,2, 2,1] 步长大小一般与池化窗口大小一致，使最终图像只有一半维度
* padding  填充，同卷积

``` python
# 池化操作
pool_img = tf.nn.max_pool(out_img, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding="SAME")
pool_img.shape        # (1, 14, 14, 1)
pool_img = tf.reshape(pool_img, (14, 14))
plt.imshow(pool_img, cmap='Greys')
```

如图，分别为原图、卷积、池化得特征图像，保留了原图像的特征同时大大降低了维度！

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20210330104400679.png" alt="image-20210330104400679" style="zoom:50%;" />

参考：

tensorflow sobel算子实现 https://blog.csdn.net/miss_yan/article/details/90813029

# Day 02

### 使用CNN进行MNIST训练

模型结构如图所示。通过两次卷积、两次最大池化、两次全连接层。第一次卷积使用32个5*5的卷积核，第二次卷积使用64个5\*5的卷积核，步长为1且填充保证输出特征图大小一致；池化大小为2\*2、步长为2使池化后图像大小缩小一倍。最后一次池化后通过扁平化**Flaten**将7\*7\*64的高维图像转为一维的3136像素的特征向量，然后经过一次1024个节点（神经元）的全连接层，采用**dropout**策略随机丢弃部分节点不去“学习”以增加泛化能力防止过拟合，最终经过softmax输出为1\*1\*10的预测值。

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/20190326102325207.png" alt="在这里插入图片描述" style="zoom:50%;" />

### 构建模型

#### 卷积后全连接方式

``` python
import tensorflow as tf
from tensorflow.keras import layers
 
inputs = layers.Input(shape=(28, 28, 1))    # 输入图像大小28*28*1通道
# 第一次卷积池化，5*5*32卷积核
conv1 = layers.Conv2D(filters=32, kernel_size=5, strides=1, padding="SAME", activation="relu")(inputs)
pool1 = layers.MaxPool2D(pool_size=2, strides=2)(conv1)  # 14 * 14 * 32
# 第二次卷积池化，5*5*64卷积核
conv2 = layers.Conv2D(filters=64, kernel_size=5, strides=1, padding="SAME", activation="relu")(inputs)
pool2 = layers.MaxPool2D(pool_size=2, strides=2)(conv2)  # 7 * 7 * 64
# 扁平化，7*7*64 -> 1*1*3136
flat = layers.Flatten()(pool2)
# 全连接层，3136 -> 1024
fullc = layers.Dense(1024, activation="relu")(flat)
# 丢弃部分节点防止过拟合
keep_prob = 0.5     # 保留率
dropout = layers.Dropout(rate=keep_prob)(fullc)
# 第二个全连接层（可以不使用）
fullc2 = layers.Dense(1024, activation="relu")(dropout)
dropout2 = layers.Dropout(rate=keep_prob)(fullc2)
# 输出层, 1024 -> 10
outputs = layers.Dense(10, activation="softmax")(dropout2)
```

* layers.Conv2D：filters=卷积核个数，kernel_size=卷积核大小，strides=步长，activation=激活函数，padding=填充
* layers.MaxPool2D：poolsize=池化窗口大小，strides=池化步长
* layers.Flaten()：扁平化
* layers.Dense()：units=全连接神经元数量/节点，activation=激活函数
* layers.Dropout()：rate=保留率

#### 全局池化方式

在第二次池化后，得到7\*7\*64大小的feature map，使用一个10层（因为输出为10）的卷积核对其卷积得到7\*7\*10的feature map，再经过7\*7大小和步长的平均池化，最终得到1*1\*10大小的feature map，最后进行维度变换：

``` python
# ... pool2
# 方式二：最后一层采用全局平均池化层
conv3 = layers.Conv1D(filters=10, kernel_size=5, strides=1, padding="SAME", activation="relu")(pool2)
pool3 = layers.AvgPool2D(pool_size=7, strides=7)(conv3)
print(pool3.shape)
outputs = tf.reshape(pool3, shape=[-1, 10])
```

使用此模型时采用Adagrad优化器效果明显。

### 模型优化

``` python
# 建立模型，输入为layers.Input()对象，输出为构建模型的输出层
model = tf.keras.Model(inputs=inputs, outputs=outputs)
# 定义优化器参数：优化器类型、学习率、损失函数、评估列表
model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.3), loss='SparseCategoricalCrossentropy', metrics=['accuracy'])
```

* keras.Model    建立模型对象，参数为输入层和输出层
* model.compile  配置优化器参数，损失和评估指标
  * loss    https://tensorflow.google.cn/api_docs/python/tf/keras/losses
  * optimizer https://tensorflow.google.cn/api_docs/python/tf/keras/optimizers

### 模型训练和评估

``` python
# 模型训练
model.fit(x=train_x, y=train_y, batch_size=100, epochs=10)
# 模型评估
loss, accuracy = model.evaluate(x=test_x, y=test_y)
print(loss, accuracy)
```

* model.fit     训练模型，x=输入，y=输出，batch_size=批次，epochs=轮数
* model.evaluate   模型评估，x=测试输入，y=测试输出

> Epoch 1/5 600/600 [==============================] 132s 220ms/step - loss: 0.1072 - accuracy: 0.9691
> Epoch 2/5 600/600 [==============================] - 116s 194ms/step - loss: 0.0785 - accuracy: 0.9764
> Epoch 3/5 600/600 [==============================] - 115s 192ms/step - loss: 0.0698 - accuracy: 0.9784
> Epoch 4/5 600/600 [==============================] - 117s 194ms/step - loss: 0.0666 - accuracy: 0.9811
> Epoch 5/5 600/600 [==============================] - 117s 194ms/step - loss: 0.0632 - accuracy: 0.9827
> 313/313 [==============================] - 5s 15ms/step - loss: 0.1233 - accuracy: 0.9655 0.12332648038864136 0.965499997138977

### 模型预测

* model.predict：x=待预测输入

``` python
# 取一张图片输入，转为四维，对应Inputs格式
x_predict = tf.reshape(x_test[0], shape=[-1, 28, 28, 1])
# 执行预测，输出结果与Outputs格式相同
y_predict = model.predict(x=x_predict)[0]
print(tf.argmax(y_predict).numpy())
```

> 7

参考博客：

深度学习手记（七）之MNIST实现CNN模型 https://blog.csdn.net/llh_1178/article/details/88817072

tensorflow——MNIST（CNN实现） https://blog.csdn.net/u012198575/article/details/96316436

CNN手写数字代码实现：https://www.bilibili.com/video/BV1Wt411C75s?p=43

# Day 03

**全局平均池化**是为了替代传统**全连接层**，在卷积神经网络中，隐含层经过多次卷积、池化后，得到的特征图feature map大小越来越小，但通道数（厚度）越来越大，传统的全连接层方式是通过flaten扁平化操作将其“拉伸”成一维特征向量，二全局平均池化的做法是取最后一个特征图每一层（通道）的平均值，即是一维数据。

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/20180201141956028.jpg" alt="img" style="zoom:50%;" />

卷积网络在ImageNet比赛对比：

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20210331152420456.png" alt="image-20210331152420456" style="zoom:80%;" />

可以看出层数越来越多，另一个显著差别就是全连接层数量大幅降低，原因是全连接层参数过多计算量大，替换为全局平均池化效率将显著提高，因此在神经网络中应尽量减少全连接层的使用。

### 其他卷积网络

* 图像**目标检测**
  * Yolo：GoogleNet + bounding boxes
  * Faster-RCNN：VGG, RestNet
  * SSD：VGG+region proposals

### 疑惑

关于训练时的调参问题，发现虽然已经构建好模型，但不同的loss算法、学习率所得结果大相径庭，有时候即使相同的loss算法，学习率0.3时可以收敛，但学习率0.9时却不能......对模型的最后一层的处理方式，全连接处理时的dropout学习保留率不同、全连接层数都会影响训练，或使用全局平均池化方式替代全连接反而不能得到有效训练结果......

似乎找到正确的学习参数比构建模型本身更困难！

调参技巧：不设置学习率，让Keras的Model会自动找到合适学习率。

* 网络结构
  * 全连接 --> 卷积、池化
  * 激活函数：relu、softmax、sigmoid
  * 深度（层数）、卷积核大小、数量
  * dropout保留率大小
* 损失函数
  * SGD
  * Adam
  * Adagrad ...
* 学习率

如果训练时精度卡住，换一种损失函数试试，再考虑调整网络结构等。

# Day 04

**数据归一化**：样本中某些特征值过大过过小，计算误差时标准差是其他数据的几个量级，直接影响到数据的预测结果偏差大。归一化将全部样本值归一到0~1区间内，减弱少数极端样本对整体结果的影响。归一化公式：
$$
X^{'} = \frac{x - min}{max - min}  \\
X^{''} = X'(mx - mi) + mi \ (mx通常取1，mi通常取0)
$$
缺陷：受最大最小值影响大，如果最值为异常点，则仍受到干扰。**鲁棒性**差，即稳定性较差，只适合传统精确的小数据场景，在数据中含有异常数据时效果差。

**数据标准化**：将原始数据变换为**标准正态分布**，即变换到均值为0，标准差为1的范围内。标准化公式：mean数据平均值，sigma数据标准差
$$
X' = \frac{x - mean} {σ}
$$
标准化鲁棒性强，少量异常点对平均值的影响不大，从而方差受影响小。

**K-NN算法**：如果一个特征空间中的k个最相似（最近邻）的样本属于某一类别，则判定该样本也属于这个类别。关键在于计算样本距离和K值选择（多少个最近邻居）。简单、易理解、无需训练，计算量大内存开销大，性能低，K值选择是关键，针对小数据场景。

**超参数**：在分类等算法中需要手动指定的参数，如K-NN中的K值。网格搜索做的就是遍历一组超参数得到不同参数下的预估结果。

**朴素贝叶斯**Naive Bayes：古典数学理论，稳定的分类器，算法简单，常用于文本分类，准确度高、速度快。缺点是too naive，仅在样本属性独立性的假设前提下有效。

# Day 05

### 验证码识别

用到Python的图像处理库pillow，数值分析库numpy，绘图库matplotlib，光学符号识别库pytesseract。

思路是先将验证码转为灰度图，再转换为ndarray的二维数组，删除背景噪声像素（与文字像素相比值更大，颜色更浅偏白）

``` python
from PIL import Image
 
img = Image.open('captcha2.jpg')
img = img.convert('L')
 
import numpy as np
import matplotlib.pyplot as plt
 
img = np.array(img)
plt.imshow(img, cmap='gray')
```

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20210403191739099.png" alt="image-20210403191739099" style="zoom:50%;" />

遍历像素，将超过灰度值超过120的置为255，即白色；灰度值低于120的置为0，即黑色：

``` python
height = img.shape[0]
width = img.shape[1]
threshold = 120  # 像素阈值
for h in range(height):
    for w in range(width):
        if img[h][w] > threshold:
            img[h][w] = 255
        else:
            imgp[h][w] = 0
plt.imshow(img, cmap='gray')
```

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20210403210530113.png" style="zoom:50%;" />

效果看起来不错，存在锯齿现象，但问题不大。

在使用pyteserract前需要先安装好tesseract，其带有识别程序和文字数据，自带有eng.traindata代表英文数字识别数据包。在使用前先设置可执行teserract的安装路径。

``` python
import pytesseract
 
pytesseract.pytesseract.tesseract_cmd = r"C:\Users\TempProgram\Tesserocr\tesseract.exe"
pytesseract.image_to_string(im).strip().lower()
```

> 'z2zh'

能准确识别出Z和2，下载几张新的图片均能够准确识别。看来这验证码难度不大，不需要再做CNN神经网络训练任务。

将以上验证码处理识别程序和前面的模拟登录结合，唯一的遗憾是整个Python程序外还需要安装tesseract软件。

**下周计划**：使用CNN卷积神经网络识别验证码，与传统的OCR识别效果对比。

分析：数字0-9，小写字母a-z，大写字母A-Z，一共62个类别，不采用图像分割方式完整识别四个字符一组的验证码，可能需要大量批注工作。