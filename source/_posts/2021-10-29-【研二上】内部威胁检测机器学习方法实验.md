---

title: 【研二上】内部威胁检测机器学习方法实验
date: 2021-10-30
category: 机器学习
tag: 周报

---

 

> [1]林玲莉. 基于深度信念网络的信息系统内部威胁检测方法[D].  2018.

为了解决内部威胁数据多域信息难以有效利用的问题，本文使用深度置信网络进一步提取审计日志的特征，以获取不同类型日志数据间的高维隐含特征，然后输入到SVM进行训练。

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20211030100512408.png" alt="image-20211030100512408" style="zoom:67%;" />

使用数据集：CERT r4.2，1000个用户，502天操作日志记录

数据统计：总323,510日记录，974异常行为记录，占0.3%

进一步地，在输入模型前对DBN特征进行聚类，以学习不同行为模式下的分类模型：

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20211030105352912.png" alt="image-20211030105352912" style="zoom: 60%;" />

实验使用2/3数据作为训练集，评估指标为：Accuracy Rate、Detection Rate、False Positive Rate

使用DBN得到80.49%的检出率，使用DBN+聚类可以达到92.81%的检出率。说明特征聚类非常有效。

上周论文“*内部威胁数据上的细粒度分级机器学习检测*”结果如下（50%训练集）：

![image-20211030180415993](https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20211030180415993.png)

### Random Forest Classifier

使用按天进行实例分类的CERT r4.2数据集：

* 数据统计：总实例330,452，异常实例966

* 实例特征维数：500

参数设置：300棵决策树，每棵树最大深度25

``` python
# 实例数据加载，分离特征和标签
import pandas as pd
 
day_instance_file = '../dayr4.2.csv'
day_instance_data = pd.read_csv(day_instance_file)
day_instance_data.head()
 
# 数据表前7列是时间、user信息
# 中间500列是按日划分的特征数据
# 最后一列insider是标签：[0,1,2,3]，代表正常实例和3种恶意行为
# 将三种场景的恶意行为标签重新为：1
 
feature_data = day_instance_data.iloc[:,7:-1].values
label_data = day_instance_data.iloc[:,-1:].values
label_data[label_data>0] = 1  # 将恶意行为统一标签为 1
label_data = label_data.ravel()  # 转置列-->行
 
feature_data.shape    # (330452, 500)
label_data.shape
 
# 进行数据集划分
from sklearn.model_selection import train_test_split
 
X_train, X_test, y_train, y_test = train_test_split(feature_data, label_data,
                                        test_size=0.3, random_state=66,   # 70%训练集
                                        stratify=label_data)  # 按照良性:恶性比例得到相同分布
X_train.shape  # (231316, 500)
X_test.shape     # (99136, 500)
 
# 实例化随机森林分类器
from sklearn.ensemble import RandomForestClassifier
 
rfc = RandomForestClassifier(n_estimators=300,
                             max_depth=None, random_state=66)  # 设置随机森林参数
rfc.fit(X_train, y_train)  # 进行模型拟合
 
# 进行预测及评估
from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score, confusion_matrix
 
fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)
auc_score = auc(fpr, tpr)
Pr = precision_score(y_test, y_pred)
DR = recall_score(y_test, y_pred)
F1 = f1_score(y_test, y_pred)
print(f"Detect rate: {DR}\r\nPr: {Pr}\r\nF1: {F1}\r\nAUC: {auc_score}")
# print(classification_report(y_test, y_pred))
```

> ```
>             precision    recall  f1-score   support
>
>         0       1.00      1.00      1.00     98846
>         1       1.00      0.47      0.64       290
> ```

实验结果接近“数据粒度分级”论文的实验结果，检出异常数据47%。接下来使用XGBoost方法进行实验

### XGBoost

#### 集成学习-提升方法

参数设置：300棵提升树，每棵树最大深度25

``` python
# 使用XGBoost进行分类预测
from xgboost import XGBClassifier
 
XGB = XGBClassifier(n_estimators=300, max_dept=25, random_state=66)
XGB.fit(X_train, y_train)
 
y_pred = XGB.predict(X_test)
 
fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)
auc_score = auc(fpr, tpr)
Pr = precision_score(y_test, y_pred)
DR = recall_score(y_test, y_pred)
F1 = f1_score(y_test, y_pred)
print(f"Detect rate: {DR}\r\nPr: {Pr}\r\nF1: {F1}\r\nAUC: {auc_score}")
# print(classification_report(y_test, y_pred))
```

> ```
>             precision    recall  f1-score   support
>
>         0       1.00      1.00      1.00     98846
>         1       1.00      0.88      0.94       290
> ```

实验结果比”数据粒度分级”论文结果(75%)稍好（训练集更多），检出88%异常。接近DBN+聚类+SVM分类的最优结果（92%）

#### 模型交叉验证

``` python
# 对XGBoost模型进行交叉验证、绘制学习曲线
from sklearn.model_selection import KFold
 
cv = KFold(n_splits=5, shuffle=True, random_state=66)
estimator = XGBClassifier(n_estimators=300, max_dept=None, random_state=66)
train_sizes, train_scores, test_scores = learning_curve(estimator, X_train, y_train, shuffle=True, cv=cv, n_jobs=-1, random_state=66)
ax = plt.gca()
ax.set_title("XGBoost")
ax.set_xlabel("Training examples")
ax.set_ylabel("Score")
ax.grid()
ax.plot(train_sizes, np.mean(train_scores, axis=1), 'o-', color='r', label="Training score")
ax.plot(train_sizes, np.mean(test_scores, axis=1), 'o-', color='g', label="Cross val score")
ax.legend(loc="best")
plt.show()
```

K折交叉验证结果：XGBoost模型在训练集上的表现能力较好

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20211031133841133.png" alt="image-20211031133841133" style="zoom: 80%;" />

### 重要特征筛选

CERT r4.2数据集按天进行实例划分后，每个实例包含500维特征，导致模型训练很慢，希望按照特征重要性去除对分类结果不重要的特征。分别提取6类日志数据的Top 10重要的特征，组成60维特征的数据进行实验：

``` python
# 按列分割6类特征
user_feature = feature_data[:,:26]  # 用户特征
logon_feature = feature_data[:,26:41]  # 登录特征
device_feature = feature_data[:,41:59]  # 设备特征
file_feature = feature_data[:,59:269]  # 文件特征
mail_feature = feature_data[:,269:311]  # 邮件特征
http_feature = feature_data[:,311:]  # HTTP特征  
http_feature.shape  # (330452, 189)
 
# 分析每一类特征下子特征的重要性排名
XGB = XGBClassifier(n_estimators=50, max_depth=25, random_state=66)
XGB.fit(http_feature, label_data)  # 每次运行调换不同参数
fig,ax = plt.subplots(figsize=(10,15))
plot_importance(XGB,height=0.5, max_num_features=10,ax=ax, importance_type='gain')
plt.show()
 
# 按照筛选出的n个重要特征筛选数据
important_feature_data = feature_data[:,n_important_feature]
important_feature_data.shape  # (330452, 60)
```

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20211031164642970.png" alt="image-20211031164642970" style="zoom:67%;" />

筛选出6类别60个重要的特征，先进行随机森林训练测试：

> ```
>               precision    recall  f1-score   support
>
>            0       1.00      1.00      1.00     98846
>            1       0.99      0.78      0.87       290
> ```

检测结果(78%)比论文(44%)有很大提高，验证了多维数据中的噪声对RF分类影响较大。再进行XGBoost训练测试：

> ```
>               precision    recall  f1-score   support
>
>            0       1.00      1.00      1.00     98846
>            1       0.98      0.91      0.94       290
> ```

实验结果(91%)比全部特征测试结果(88%)有一点提升，且训练时间缩短很多，几乎接近DBN+聚类+SVM最优结果(92%)，且错检率更低、精度更高

### Inspire

虽然浅层机器学习(随机森林、XGBoost等)能够在内部威胁检测问题上表现出良好的性能，但瓶颈在于难以充分利用多域、高维、复杂的用户行为数据（后来的实验表明，提取出对分类问题有效的n个重要特征后，XGBoost表现优异）。深度学习方法能够利用隐含层提取复杂数据的多重、不同层次的隐藏特征，因此在内部威胁检测上能够发现更多的恶意行为的表达。

由于内部威胁数据是由员工（实体）及其行为（实例）组成的，因此检测问题也分为：基于实体的检测和基于实例的检测。近年来，主要的深度学习方法包括：深度前馈神经网络、卷积神经网络、递归神经网络和图神经网络。

就GNN而言，基本方法是通过实体关系构建图，输入到图卷积网络中强化节点特征做出分类。上周阅读了首篇基于GCN的威胁检测论文，文章通过员工邮件关系和特征相似度构建图，经过两层GCN对实体进行分类，但最后实验的训练和测试过程仅取400个良性实体数据，其中包含70个恶性实体。这与真实情况偏差过大，真实的内部威胁仅有很少部分为恶性。个人认为，目前的GNN威胁检测方法并不能经受考验，其一是图的构建大多利用员工邮件联系、上下级关系，这样构造出的图结构对于要解决的图问题并没有很大帮助，原因是恶意实体大部分时候的行为是良性的，当恶意行为发生时，员工与其上下级、邮件接受者之间并无相关性，因此聚集邻节点信息时反而降低自身被检测的风险；其二，恶意员工往往是独立的，并不与其他恶意员工具有关联，所以不应该使用员工构建图，而应该使用恶意行为，因为同一类的恶意行为往往是相似的。

另一个观点是，日志文件是属于不同域的，也就是数据包含6类特征，目前的方法在训练时都是将全部特征简单的进行concat，从而丢失了不同域特征之间的关联性。如果使用图网络对问题建模，应该将不同域作为节点（异构图节点），聚集不同域的特征信息后进行分类，可能会有更好的表现。其次，受开篇文章的启发，尝试特征融合方法、特征聚类方法，在输入模型之前（早期）融合关键特征信息。

另外，参考“细粒度分级威胁检测”论文的实验结果，使用50%以上的数据作为训练集是在理想实验环境下进行的，尽管能够取得很好的表现。作者提出，**随机抽取20%的实验数据用于训练，在整个数据集上进行测试**，更能接近实际问题。下周将阅读该作者的最新论文：*使用无监督集成方法解决内部威胁异常检测(2021)*

> Le, D. C., & Zincir-Heywood, N. (2021). *Anomaly Detection for Insider Threats Using Unsupervised Ensembles. IEEE Transactions on Network and Service Management, 18(2), 1152–1164.* doi:10.1109/tnsm.2021.3071928

以及特征融合文章：*内部威胁检测的多域信息融合(2013)*：

> Eldardiry, H., Bart, E., Juan Liu, Hanley, J., Price, B., & Brdiczka, O. (2013). *Multi-Domain Information Fusion for Insider Threat Detection. 2013 IEEE Security and Privacy Workshops.*
> doi:10.1109/spw.2013.14